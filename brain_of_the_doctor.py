from dotenv import load_dotenv
load_dotenv()

import os
import sys
import base64
import time
import hashlib
import shutil
import tempfile
from functools import lru_cache
from groq import Groq, GroqError

# Try to get API key from environment variables first
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

def get_api_key():
    """Get API key from Streamlit secrets or environment variables"""
    try:
        import streamlit as st
        return st.secrets["GROQ_API_KEY"]
    except (ImportError, KeyError, AttributeError):
        return os.environ.get("GROQ_API_KEY")

def test_api_key(api_key):
    """Test if the provided API key is valid by making a minimal request"""
    try:
        client = Groq(api_key=api_key)
        # Make a minimal request to list available models or similar
        models = client.models.list()
        if models:
            return True
        return False
    except Exception as e:
        print(f"API key test failed: {str(e)}")
        return False

def handle_long_path(file_path):
    """Handle long file paths by creating a shorter temporary path"""
    try:
        # Create a temporary directory
        temp_dir = tempfile.mkdtemp()
        # Get the file extension
        _, ext = os.path.splitext(file_path)
        # Create a new shorter path
        new_path = os.path.join(temp_dir, f"temp{ext}")
        # Copy the file to the new location
        shutil.copy2(file_path, new_path)
        return new_path
    except Exception as e:
        print(f"Error handling long path: {str(e)}")
        return file_path

def encode_image(image_path, max_size=256):
    """Convert image to base64 string with optional resizing"""
    try:
        # Handle long paths
        image_path = handle_long_path(image_path)
        
        import cv2
        # Read and optionally resize image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Could not read image file")
            
        height, width = img.shape[:2]
        if max(height, width) > max_size:
            scale = max_size / max(height, width)
            img = cv2.resize(img, (0,0), fx=scale, fy=scale)
            
        # Encode with lower quality
        _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 60])
        encoded = base64.b64encode(buffer).decode('utf-8')
        return encoded
        
    except Exception:
        # Fallback to original method if OpenCV fails
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

PRESCRIPTION_TEMPLATE = """
PRESCRIPTION
Date: {date}
Patient: {patient_name}
Diagnosis: {diagnosis}

Medications:
{medications}

Instructions:
{instructions}

Doctor: AI Doctor
"""

def generate_prescription(diagnosis, language="English"):
    """Generate a prescription based on diagnosis."""
    from datetime import datetime

    if not diagnosis or not isinstance(diagnosis, str):
        raise ValueError("Diagnosis must be a non-empty string")

    # Clean up the diagnosis string to get the primary condition
    # Example: "DIAGNOSIS:\n- Condition identified: Dandruff" -> "Dandruff"
    primary_diagnosis = diagnosis.splitlines()
    for line in primary_diagnosis:
        if "condition identified" in line.lower():
            primary_diagnosis = line.split(":")[-1].strip()
            break
    else:
        # If the specific line isn't found, use the first non-empty line
        primary_diagnosis = next((line for line in diagnosis.splitlines() if line.strip()), diagnosis)


    meds_map = {
        "Dandruff": {
            "English": {
                "medications": ["Ketoconazole 2% shampoo", "Selenium sulfide 2.5% shampoo"],
                "instructions": ["Use medicated shampoo twice weekly.", "Leave on scalp for 5-10 minutes."],
                "follow_up": "Follow up in 2 weeks if condition persists.",
            },
            "Hindi": {
                "medications": ["рдХреАрдЯреЛрдХреЛрдирд╛рдЬрд╝реЛрд▓ 2% рд╢реИрдореНрдкреВ", "рд╕реЗрд▓реЗрдирд┐рдпрдо рд╕рд▓реНрдлрд╛рдЗрдб 2.5% рд╢реИрдореНрдкреВ"],
                "instructions": ["рд╕рдкреНрддрд╛рд╣ рдореЗрдВ рджреЛ рдмрд╛рд░ рдореЗрдбрд┐рдХреЗрдЯреЗрдб рд╢реИрдореНрдкреВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред", "5-10 рдорд┐рдирдЯ рддрдХ рд╕реНрдХреИрд▓реНрдк рдкрд░ рд▓рдЧрд╛ рд░рд╣рдиреЗ рджреЗрдВред"],
                "follow_up": "рдпрджрд┐ рд╕реНрдерд┐рддрд┐ рдмрдиреА рд░рд╣рддреА рд╣реИ рддреЛ 2 рд╕рдкреНрддрд╛рд╣ рдореЗрдВ рдлреЙрд▓реЛ-рдЕрдк рдХрд░реЗрдВред",
            },
            "Marathi": {
                "medications": ["рдХреАрдЯреЛрдХреЛрдирд╛рдЭреЛрд▓ реи% рд╢рд╛рдореНрдкреВ", "рд╕реЗрд▓реЗрдирд┐рдпрдо рд╕рд▓реНрдлрд╛рдЗрдб реи.рел% рд╢рд╛рдореНрдкреВ"],
                "instructions": ["рдЖрдард╡рдбреНрдпрд╛рддреВрди рджреЛрдирджрд╛ рдФрд╖рдзреА рд╢рд╛рдореНрдкреВ рд╡рд╛рдкрд░рд╛рд╡рд╛.", "рел-резреж рдорд┐рдирд┐рдЯреЗ рд╕реНрдХреЕрд▓реНрдкрд╡рд░ рдареЗрд╡рд╛."],
                "follow_up": "рд╕реНрдерд┐рддреА рдХрд╛рдпрдо рд░рд╛рд╣рд┐рд▓реНрдпрд╛рд╕ реи рдЖрдард╡рдбреНрдпрд╛рдВрдиреА рдкреБрдиреНрд╣рд╛ рд╕рдВрдкрд░реНрдХ рд╕рд╛рдзрд╛.",
            },
        }
    }
    
    # Multilingual fallback messages
    fallback_treatment = {
        "English": {
            "medications": ["No specific medication found for this diagnosis."],
            "instructions": ["Please consult a healthcare professional for a personalized treatment plan."],
            "follow_up": "Follow up with a doctor as soon as possible.",
        },
        "Hindi": {
            "medications": ["рдЗрд╕ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП рдХреЛрдИ рд╡рд┐рд╢рд┐рд╖реНрдЯ рджрд╡рд╛ рдирд╣реАрдВ рдорд┐рд▓реАред"],
            "instructions": ["рд╡реНрдпрдХреНрддрд┐рдЧрдд рдЙрдкрдЪрд╛рд░ рдпреЛрдЬрдирд╛ рдХреЗ рд▓рд┐рдП рдХреГрдкрдпрд╛ рдХрд┐рд╕реА рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рд▓реЗрдВред"],
            "follow_up": "рдпрдерд╛рд╢реАрдШреНрд░ рдбреЙрдХреНрдЯрд░ рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред",
        },
        "Marathi": {
            "medications": ["рдпрд╛ рдирд┐рджрд╛рдирд╛рд╕рд╛рдареА рдХреЛрдгрддреЗрд╣реА рд╡рд┐рд╢рд┐рд╖реНрдЯ рдФрд╖рдз рд╕рд╛рдкрдбрд▓реЗ рдирд╛рд╣реА."],
            "instructions": ["рд╡реИрдпрдХреНрддрд┐рдХреГрдд рдЙрдкрдЪрд╛рд░ рдпреЛрдЬрдиреЗрд╕рд╛рдареА рдХреГрдкрдпрд╛ рдЖрд░реЛрдЧреНрдпрд╕реЗрд╡рд╛ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдЪрд╛ рд╕рд▓реНрд▓рд╛ рдШреНрдпрд╛."],
            "follow_up": "рд╢рдХреНрдп рддрд┐рддрдХреНрдпрд╛ рд▓рд╡рдХрд░ рдбреЙрдХреНрдЯрд░рд╛рдВрд╢реА рд╕рдВрдкрд░реНрдХ рд╕рд╛рдзрд╛.",
        },
    }

    date = datetime.now().strftime("%d/%m/%Y")
    
    # Find treatment for the primary diagnosis, or use the multilingual fallback
    treatment_options = meds_map.get(primary_diagnosis, fallback_treatment)
    treatment = treatment_options.get(language, treatment_options.get("English"))


    templates = {
        "English": """
PRESCRIPTION
Date: {date}
Patient: [Patient Name]
Diagnosis: {diagnosis}

Medications:
{medications}

Instructions:
{instructions}

Follow-up: {follow_up}

Doctor: AI Doctor
""",
        "Hindi": """
рдиреБрд╕реНрдЦрд╛
рджрд┐рдирд╛рдВрдХ: {date}
рд░реЛрдЧреА: [рд░реЛрдЧреА рдХрд╛ рдирд╛рдо]
рдирд┐рджрд╛рди: {diagnosis}

рджрд╡рд╛рдЗрдпрд╛рдВ:
{medications}

рдирд┐рд░реНрджреЗрд╢:
{instructions}

рдлреЙрд▓реЛ-рдЕрдк: {follow_up}

рдбреЙрдХреНрдЯрд░: AI Doctor
""",
        "Marathi": """
рдФрд╖рдзреЛрдкрдЪрд╛рд░
рджрд┐рдирд╛рдВрдХ: {date}
рд░реБрдЧреНрдг: [рд░реБрдЧреНрдгрд╛рдЪреЗ рдирд╛рд╡]
рдирд┐рджрд╛рди: {diagnosis}

рдФрд╖рдзреЗ:
{medications}

рд╕реВрдЪрдирд╛:
{instructions}

рдкреБрдиреНрд╣рд╛ рддрдкрд╛рд╕рдгреА: {follow_up}

рдбреЙрдХреНрдЯрд░: AI Doctor
"""
    }

    template = templates.get(language, templates["English"])

    return template.format(
        date=date,
        diagnosis=diagnosis, # Keep the full original diagnosis for display
        medications="\n".join(f"- {med}" for med in treatment["medications"]),
        instructions="\n".join(f"- {inst}" for inst in treatment["instructions"]),
        follow_up=treatment["follow_up"],
    )

@lru_cache(maxsize=100)
def analyze_image_with_query(query, encoded_image, language="English", model="llama3-8b-8192"):
    """Analyze image with text query using GROQ's vision model with caching"""
    import logging
    if not query or not encoded_image:
        logging.error("Missing required parameters for analyze_image_with_query")
        return "Error: Missing required parameters for image analysis."
        
    client = Groq(api_key=get_api_key())
    
    # Since llama3-8b-8192 doesn't support vision, we'll analyze the text query
    # and provide guidance based on the image context
    logging.info("Vision model not available, falling back to text analysis with image context")
    
    # Language-specific prompts for image-based analysis
    language_prompts = {
        "English": """You are a dermatology specialist AI assistant. A patient has uploaded an image of their skin condition and provided the following description. 
        Please analyze their symptoms and provide a comprehensive diagnosis.
        
        For skin conditions like dandruff, look for these symptoms in their description:
        1. White or yellowish flakes on the scalp
        2. Itchy scalp
        3. Dry or oily scalp
        4. Redness or inflammation
        5. Any visible skin changes or rashes
        
        Provide your analysis in this format:
        
        DIAGNOSIS:
        - Condition identified (based on described symptoms)
        - Severity level (Mild/Moderate/Severe)
        - Key symptoms mentioned
        
        RECOMMENDATIONS:
        - Immediate care steps
        - Lifestyle changes
        - Products to use/avoid
        
        PRESCRIPTION:
        - Specific medications or treatments
        - Application instructions
        - Follow-up timeline
        
        Note: This analysis is based on the patient's description. For more accurate diagnosis, please consult a healthcare professional.""",
        
        "Hindi": """рдЖрдк рдПрдХ рддреНрд╡рдЪрд╛ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ AI рд╕рд╣рд╛рдпрдХ рд╣реИрдВред рдПрдХ рд░реЛрдЧреА рдиреЗ рдЕрдкрдиреА рддреНрд╡рдЪрд╛ рдХреА рд╕реНрдерд┐рддрд┐ рдХреА рддрд╕реНрд╡реАрд░ рдЕрдкрд▓реЛрдб рдХреА рд╣реИ рдФрд░ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд╡рд┐рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд┐рдпрд╛ рд╣реИред
        рдХреГрдкрдпрд╛ рдЙрдирдХреЗ рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ рдФрд░ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдирд┐рджрд╛рди рдкреНрд░рджрд╛рди рдХрд░реЗрдВред
        
        рд░реВрд╕реА рдЬреИрд╕реА рддреНрд╡рдЪрд╛ рдХреА рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП, рдЙрдирдХреЗ рд╡рд┐рд╡рд░рдг рдореЗрдВ рдЗрди рд▓рдХреНрд╖рдгреЛрдВ рдХреЛ рджреЗрдЦреЗрдВ:
        1. рд╕реНрдХреИрд▓реНрдк рдкрд░ рд╕рдлреЗрдж рдпрд╛ рдкреАрд▓реЗ рд░рдВрдЧ рдХреЗ рдлреНрд▓реЗрдХреНрд╕
        2. рдЦреБрдЬрд▓реА рд╡рд╛рд▓рд╛ рд╕реНрдХреИрд▓реНрдк
        3. рд╕реВрдЦрд╛ рдпрд╛ рддреИрд▓реАрдп рд╕реНрдХреИрд▓реНрдк
        4. рд▓рд╛рд▓рд┐рдорд╛ рдпрд╛ рд╕реВрдЬрди
        5. рдХреЛрдИ рджреГрд╢реНрдп рддреНрд╡рдЪрд╛ рдкрд░рд┐рд╡рд░реНрддрди рдпрд╛ рдЪрдХрддреНрддреЗ
        
        рдЕрдкрдирд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЗрд╕ рдкреНрд░рд╛рд░реВрдк рдореЗрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВ:
        
        рдирд┐рджрд╛рди:
        - рдкрд╣рдЪрд╛рдиреА рдЧрдИ рд╕реНрдерд┐рддрд┐ (рд╡рд░реНрдгрд┐рдд рд▓рдХреНрд╖рдгреЛрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░)
        - рдЧрдВрднреАрд░рддрд╛ рд╕реНрддрд░ (рд╣рд▓реНрдХрд╛/рдордзреНрдпрдо/рдЧрдВрднреАрд░)
        - рдореБрдЦреНрдп рд▓рдХреНрд╖рдг
        
        рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ:
        - рддрддреНрдХрд╛рд▓ рджреЗрдЦрднрд╛рд▓ рдХреЗ рдХрджрдо
        - рдЬреАрд╡рдирд╢реИрд▓реА рдореЗрдВ рдкрд░рд┐рд╡рд░реНрддрди
        - рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ/рдмрдЪрдиреЗ рдХреЗ рдЙрддреНрдкрд╛рдж
        
        рдиреБрд╕реНрдЦрд╛:
        - рд╡рд┐рд╢рд┐рд╖реНрдЯ рджрд╡рд╛рдПрдВ рдпрд╛ рдЙрдкрдЪрд╛рд░
        - рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдирд┐рд░реНрджреЗрд╢
        - рдлреЙрд▓реЛ-рдЕрдк рд╕рдордпрд░реЗрдЦрд╛
        
        рдиреЛрдЯ: рдпрд╣ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд░реЛрдЧреА рдХреЗ рд╡рд┐рд╡рд░рдг рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рд╣реИред рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдПрдХ рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВред""",
        
        "Marathi": """рддреБрдореНрд╣реА рдПрдХ рддреНрд╡рдЪрд╛рд░реЛрдЧ рддрдЬреНрдЬреНрдЮ AI рд╕рд╣рд╛рдпреНрдпрдХ рдЖрд╣рд╛рдд. рдПрдХ рд░реБрдЧреНрдгрд╛рдиреЗ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рддреНрд╡рдЪреЗрдЪреНрдпрд╛ рд╕реНрдерд┐рддреАрдЪреЗ рдЪрд┐рддреНрд░ рдЕрдкрд▓реЛрдб рдХреЗрд▓реЗ рдЖрд╣реЗ рдЖрдгрд┐ рдЦрд╛рд▓реАрд▓ рд╡рд░реНрдгрди рдкреНрд░рджрд╛рди рдХреЗрд▓реЗ рдЖрд╣реЗ.
        рдХреГрдкрдпрд╛ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рд╛ рдЖрдгрд┐ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдирд┐рджрд╛рди рджреНрдпрд╛.
        
        рдХреЛрдВрдбреНрдпрд╛рд╕рд╛рд░рдЦреНрдпрд╛ рддреНрд╡рдЪреЗрдЪреНрдпрд╛ рд╕реНрдерд┐рддреАрдВрд╕рд╛рдареА, рддреНрдпрд╛рдВрдЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рдд рдпрд╛ рд▓рдХреНрд╖рдгреЗ рд╢реЛрдзрд╛:
        1. рдбреЛрдХреНрдпрд╛рд╡рд░ рдкрд╛рдВрдврд░реЗ рдХрд┐рдВрд╡рд╛ рдкрд┐рд╡рд│реЗ рдлреНрд▓реЗрдХреНрд╕
        2. рдЦрд╛рдЬ рд╕реБрдЯрдгрд╛рд░реЗ рдбреЛрдХреЗ
        3. рдХреЛрд░рдбреЗ рдХрд┐рдВрд╡рд╛ рддреИрд▓рдпреБрдХреНрдд рдбреЛрдХреЗ
        4. рд▓рд╛рд▓рд╕рд░рдкрдгрд╛ рдХрд┐рдВрд╡рд╛ рд╕реВрдЬ
        5. рдХреЛрдгрддреЗрд╣реА рджреГрд╢реНрдп рддреНрд╡рдЪрд╛ рдмрджрд▓ рдХрд┐рдВрд╡рд╛ рдкреБрд░рд│
        
        рддреБрдордЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдпрд╛ рд╕реНрд╡рд░реВрдкрд╛рдд рджреНрдпрд╛:
        
        рдирд┐рджрд╛рди:
        - рдУрд│рдЦрд▓реЗрд▓реА рд╕реНрдерд┐рддреА (рд╡рд░реНрдгрди рдХреЗрд▓реЗрд▓реНрдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреНрдпрд╛ рдЖрдзрд╛рд░реЗ)
        - рдЧрдВрднреАрд░рддрд╛ рдкрд╛рддрд│реА (рд╣рд▓рдХреА/рдордзреНрдпрдо/рдЧрдВрднреАрд░)
        - рдореБрдЦреНрдп рд▓рдХреНрд╖рдгреЗ
        
        рд╢рд┐рдлрд╛рд░рд╕реА:
        - рддреНрд╡рд░рд┐рдд рдХрд╛рд│рдЬреАрдЪреЗ рдкрд╛рд╡рд▓реЗ
        - рдЬреАрд╡рдирд╢реИрд▓реА рдмрджрд▓
        - рд╡рд╛рдкрд░рдгреНрдпрд╛рд╕рд╛рдареА/рдЯрд╛рд│рдгреНрдпрд╛рд╕рд╛рдареА рдЙрддреНрдкрд╛рджрдиреЗ
        
        рдФрд╖рдзреЛрдкрдЪрд╛рд░:
        - рд╡рд┐рд╢рд┐рд╖реНрдЯ рдФрд╖рдзреЗ рдХрд┐рдВрд╡рд╛ рдЙрдкрдЪрд╛рд░
        - рд╡рд╛рдкрд░рдгреНрдпрд╛рдЪреНрдпрд╛ рд╕реВрдЪрдирд╛
        - рдкреБрдиреНрд╣рд╛ рддрдкрд╛рд╕рдгреА рд╡реЗрд│
        
        рдЯреАрдк: рд╣реЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд░реБрдЧреНрдгрд╛рдЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдЖрд╣реЗ. рдЕрдзрд┐рдХ рдЕрдЪреВрдХ рдирд┐рджрд╛рдирд╛рд╕рд╛рдареА, рдХреГрдкрдпрд╛ рд╡реИрджреНрдпрдХреАрдп рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрд╢реА рд╕рд▓реНрд▓рд╛рдорд╕рд▓рдд рдХрд░рд╛."""
    }
    
    # Get the appropriate prompt for the selected language
    system_prompt = language_prompts.get(language, language_prompts["English"])
    
    # Create a comprehensive query that includes image context
    enhanced_query = f"""Patient has uploaded an image of their skin condition and reports: {query}
    
    Please provide a detailed medical analysis based on their description. Consider common skin conditions that match their symptoms.
    
    Focus on providing helpful medical guidance while noting that this is based on their description and not a direct visual analysis."""
    
    messages = [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": enhanced_query
        }
    ]
    
    try:
        response = client.chat.completions.create(
            messages=messages,
            model=model,
            max_tokens=800
        )
        content = response.choices[0].message.content
        if not isinstance(content, str):
            content = str(content)
        if not content.strip():
            logging.error("Empty response content from analyze_image_with_query")
            return "Error: Empty response from image analysis."
        
        # Add a note about the analysis method
        note = {
            "English": "\n\nNote: This analysis is based on your description. For more accurate diagnosis, please consult a healthcare professional.",
            "Hindi": "\n\nрдиреЛрдЯ: рдпрд╣ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЖрдкрдХреЗ рд╡рд┐рд╡рд░рдг рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рд╣реИред рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдПрдХ рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВред",
            "Marathi": "\n\nрдЯреАрдк: рд╣реЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рддреБрдордЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдЖрд╣реЗ. рдЕрдзрд┐рдХ рдЕрдЪреВрдХ рдирд┐рджрд╛рдирд╛рд╕рд╛рдареА, рдХреГрдкрдпрд╛ рд╡реИрджреНрдпрдХреАрдп рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрд╢реА рд╕рд▓реНрд▓рд╛рдорд╕рд▓рдд рдХрд░рд╛."
        }
        
        return content + note.get(language, note["English"])
        
    except Exception as e:
        logging.error(f"Vision analysis failed: {str(e)}")
        if "model_not_found" in str(e):
            return analyze_text_query(query, language)
        return f"Vision analysis failed: {str(e)}"

# Validate GROQ API key
if not GROQ_API_KEY:
    error_msg = """
    ERROR: GROQ_API_KEY not found. Please make sure it's set in:
    1. Streamlit secrets (for deployment) - st.secrets["GROQ_API_KEY"]
    2. Environment variables (for local development) - GROQ_API_KEY
    3. .env file (for local development) - GROQ_API_KEY=your_key_here
    
    You can get an API key from: https://console.groq.com/
    """
    print(error_msg)
    # Don't exit in Streamlit environment, just show error
    if 'streamlit' not in sys.modules:
        sys.exit(1)
else:
    print(f"ЁЯФС API Key Status: Found (Length: {len(GROQ_API_KEY)} characters)")
    if GROQ_API_KEY.startswith("gsk_"):
        print("тЬЕ API Key format looks correct (starts with 'gsk_')")
        # Test the API key
        if test_api_key(GROQ_API_KEY):
            print("тЬЕ API Key is valid and working!")
        else:
            print("тЭМ API Key test failed - key may be invalid or expired")
    else:
        print("тЪая╕П API Key format may be incorrect (should start with 'gsk_')")

def analyze_image(image_path):
    """Analyze image using computer vision"""
    try:
        from image_analysis import analyze_image_colors
        analysis = analyze_image_colors(image_path)
        return f"Image analysis results: Dominant colors are {', '.join(analysis['dominant_colors'])}"
    except Exception as e:
        raise ValueError(f"Image analysis failed: {str(e)}")

@lru_cache(maxsize=100)
def analyze_text_query(query, language="English", model="llama3-8b-8192", max_retries=3):
    """Process text queries with GROQ API with caching"""
    import logging
    if not query or not isinstance(query, str):
        logging.error("Invalid query parameter for analyze_text_query")
        return "Error: Invalid query parameter."
        
    client = Groq(api_key=get_api_key())
    
    # Language-specific prompts
    language_prompts = {
        "English": "You are a medical specialist. Analyze the following symptoms and provide a diagnosis in English:",
        "Hindi": "рдЖрдк рдПрдХ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╣реИрдВред рдХреГрдкрдпрд╛ рдЙрддреНрддрд░ рд╣рд┐рдВрджреА рдореЗрдВ рджреЗрдВред рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ рдФрд░ рд╣рд┐рдВрджреА рдореЗрдВ рдирд┐рджрд╛рди рдкреНрд░рджрд╛рди рдХрд░реЗрдВ:",
        "Marathi": "рддреБрдореНрд╣реА рдПрдХ рд╡реИрджреНрдпрдХреАрдп рддрдЬреНрдЬреНрдЮ рдЖрд╣рд╛рдд. рдХреГрдкрдпрд╛ рдЙрддреНрддрд░ рдорд░рд╛рдареАрдд рджреНрдпрд╛. рдЦрд╛рд▓реАрд▓ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рд╛ рдЖрдгрд┐ рдорд░рд╛рдареАрдордзреНрдпреЗ рдирд┐рджрд╛рди рджреНрдпрд╛:"
    }
    
    # Get the appropriate prompt for the selected language
    system_prompt = language_prompts.get(language, language_prompts["English"])
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query}
    ]

    last_error = None
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                messages=messages,
                model=model,
                max_tokens=800
            )
            
            if not response.choices:
                logging.error("Empty response from API in analyze_text_query")
                return "Error: Empty response from text analysis."
                
            content = response.choices[0].message.content
            print("MODEL RAW OUTPUT:", repr(content))
            if not isinstance(content, str):
                content = str(content)
            if not content.strip():
                logging.error("Empty content string from analyze_text_query")
                return "Error: Empty content from text analysis."
            return content
            
        except GroqError as e:
            last_error = e
            if attempt < max_retries - 1:
                time.sleep(1 * (attempt + 1))  # Exponential backoff
                continue
            logging.error(f"API request failed after {max_retries} attempts: {str(e)}")
            return f"Text analysis failed: {str(e)}"
            
        except Exception as e:
            logging.error(f"Analysis failed: {str(e)}")
            return f"Text analysis failed: {str(e)}"

if __name__ == "__main__":
    os.system("python D:\\EDIT KAREGE\\ai-doctor-2.0-voice-and-vision\\ai-doctor-2.0-voice-and-vision\\ai_doctor_fully_fixed.py")
